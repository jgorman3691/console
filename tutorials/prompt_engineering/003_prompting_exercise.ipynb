{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import concurrent.futures\n",
    "import re\n",
    "from textwrap import dedent\n",
    "from statistics import mean\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client Initialization and helper functions\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Anthropic()\n",
    "model = \"claude-3-5-haiku-latest\"\n",
    "num_tokens = 1000\n",
    "\n",
    "\n",
    "def add_user_message(messages, text):\n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": text\n",
    "    }\n",
    "    messages.append(user_message)\n",
    "\n",
    "\n",
    "def add_assistant_message(messages, text):\n",
    "    assistant_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": text\n",
    "    }\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "\n",
    "def chat(messages, system=None, temperature=1.0, stop_sequences=[]):\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = system\n",
    "    if stop_sequences:\n",
    "        params[\"stop_sequences\"] = stop_sequences\n",
    "\n",
    "    with client.messages.stream(**params) as stream:\n",
    "        for text in stream.text_stream:\n",
    "            print(text, end=\"\", flush=True)\n",
    "    \n",
    "    message = stream.get_final_message()\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report Builder\n",
    "def generate_prompt_evaluation_report(evaluation_results):\n",
    "    total_tests = len(evaluation_results)\n",
    "    scores = [result[\"score\"] for result in evaluation_results]\n",
    "    avg_score = mean(scores) if scores else 0\n",
    "    max_possible_score = 10\n",
    "    pass_rate = (\n",
    "        100 * len([s for s in scores if s >= 7]) / total_tests\n",
    "        if total_tests\n",
    "        else 0\n",
    "    )\n",
    "\n",
    "    html = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "        <title>Prompt Evaluation Report</title>\n",
    "        <style>\n",
    "            body {{\n",
    "                font-family: Arial, sans-serif;\n",
    "                line-height: 1.6;\n",
    "                margin: 0;\n",
    "                padding: 20px;\n",
    "                color: #333;\n",
    "            }}\n",
    "            .header {{\n",
    "                background-color: #f0f0f0;\n",
    "                padding: 20px;\n",
    "                border-radius: 5px;\n",
    "                margin-bottom: 20px;\n",
    "            }}\n",
    "            .summary-stats {{\n",
    "                display: flex;\n",
    "                justify-content: space-between;\n",
    "                flex-wrap: wrap;\n",
    "                gap: 10px;\n",
    "            }}\n",
    "            .stat-box {{\n",
    "                background-color: #fff;\n",
    "                border-radius: 5px;\n",
    "                padding: 15px;\n",
    "                box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n",
    "                flex-basis: 30%;\n",
    "                min-width: 200px;\n",
    "            }}\n",
    "            .stat-value {{\n",
    "                font-size: 24px;\n",
    "                font-weight: bold;\n",
    "                margin-top: 5px;\n",
    "            }}\n",
    "            table {{\n",
    "                width: 100%;\n",
    "                border-collapse: collapse;\n",
    "                margin-top: 20px;\n",
    "            }}\n",
    "            th {{\n",
    "                background-color: #4a4a4a;\n",
    "                color: white;\n",
    "                text-align: left;\n",
    "                padding: 12px;\n",
    "            }}\n",
    "            td {{\n",
    "                padding: 10px;\n",
    "                border-bottom: 1px solid #ddd;\n",
    "                vertical-align: top;\n",
    "            }}\n",
    "            tr:nth-child(even) {{\n",
    "                background-color: #f9f9f9;\n",
    "            }}\n",
    "            .output-cell {{\n",
    "                white-space: pre-wrap;\n",
    "            }}\n",
    "            .score {{\n",
    "                font-weight: bold;\n",
    "                padding: 5px 10px;\n",
    "                border-radius: 3px;\n",
    "                display: inline-block;\n",
    "            }}\n",
    "            .score-high {{\n",
    "                background-color: #c8e6c9;\n",
    "                color: #2e7d32;\n",
    "            }}\n",
    "            .score-medium {{\n",
    "                background-color: #fff9c4;\n",
    "                color: #f57f17;\n",
    "            }}\n",
    "            .score-low {{\n",
    "                background-color: #ffcdd2;\n",
    "                color: #c62828;\n",
    "            }}\n",
    "            .output {{\n",
    "                overflow: auto;\n",
    "                white-space: pre-wrap;\n",
    "            }}\n",
    "\n",
    "            .output pre {{\n",
    "                background-color: #f5f5f5;\n",
    "                border: 1px solid #ddd;\n",
    "                border-radius: 4px;\n",
    "                padding: 10px;\n",
    "                margin: 0;\n",
    "                font-family: 'Consolas', 'Monaco', 'Courier New', monospace;\n",
    "                font-size: 14px;\n",
    "                line-height: 1.4;\n",
    "                color: #333;\n",
    "                box-shadow: inset 0 1px 3px rgba(0, 0, 0, 0.1);\n",
    "                overflow-x: auto;\n",
    "                white-space: pre-wrap; \n",
    "                word-wrap: break-word; \n",
    "            }}\n",
    "\n",
    "            td {{\n",
    "                width: 20%;\n",
    "            }}\n",
    "            .score-col {{\n",
    "                width: 80px;\n",
    "            }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"header\">\n",
    "            <h1>Prompt Evaluation Report</h1>\n",
    "            <div class=\"summary-stats\">\n",
    "                <div class=\"stat-box\">\n",
    "                    <div>Total Test Cases</div>\n",
    "                    <div class=\"stat-value\">{total_tests}</div>\n",
    "                </div>\n",
    "                <div class=\"stat-box\">\n",
    "                    <div>Average Score</div>\n",
    "                    <div class=\"stat-value\">{avg_score:.1f} / {max_possible_score}</div>\n",
    "                </div>\n",
    "                <div class=\"stat-box\">\n",
    "                    <div>Pass Rate (≥7)</div>\n",
    "                    <div class=\"stat-value\">{pass_rate:.1f}%</div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "\n",
    "        <table>\n",
    "            <thead>\n",
    "                <tr>\n",
    "                    <th>Scenario</th>\n",
    "                    <th>Prompt Inputs</th>\n",
    "                    <th>Solution Criteria</th>\n",
    "                    <th>Output</th>\n",
    "                    <th>Score</th>\n",
    "                    <th>Reasoning</th>\n",
    "                </tr>\n",
    "            </thead>\n",
    "            <tbody>\n",
    "    \"\"\"\n",
    "\n",
    "    for result in evaluation_results:\n",
    "        prompt_inputs_html = \"<br>\".join(\n",
    "            [\n",
    "                f\"<strong>{key}:</strong> {value}\"\n",
    "                for key, value in result[\"test_case\"][\"prompt_inputs\"].items()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        criteria_string = \"<br>• \".join(\n",
    "            result[\"test_case\"][\"solution_criteria\"]\n",
    "        )\n",
    "\n",
    "        score = result[\"score\"]\n",
    "        if score >= 8:\n",
    "            score_class = \"score-high\"\n",
    "        elif score <= 5:\n",
    "            score_class = \"score-low\"\n",
    "        else:\n",
    "            score_class = \"score-medium\"\n",
    "\n",
    "        html += f\"\"\"\n",
    "            <tr>\n",
    "                <td>{result[\"test_case\"][\"scenario\"]}</td>\n",
    "                <td class=\"prompt-inputs\">{prompt_inputs_html}</td>\n",
    "                <td class=\"criteria\">• {criteria_string}</td>\n",
    "                <td class=\"output\"><pre>{result[\"output\"]}</pre></td>\n",
    "                <td class=\"score-col\"><span class=\"score {score_class}\">{score}</span></td>\n",
    "                <td class=\"reasoning\">{result[\"reasoning\"]}</td>\n",
    "            </tr>\n",
    "        \"\"\"\n",
    "\n",
    "    html += f\"\"\"\n",
    "            </tbody>\n",
    "        </table>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PromptEvaluator Implementation\n",
    "class PromptEvaluator:\n",
    "    def __init__(self, max_concurrent_tasks=2):\n",
    "        self.max_concurrent_tasks = max_concurrent_tasks\n",
    "\n",
    "    def render(self, template_string, variables):\n",
    "        placeholders = re.findall(r\"{([^{}]+)}\", template_string)\n",
    "\n",
    "        result = template_string\n",
    "        for placeholder in placeholders:\n",
    "            if placeholder in variables:\n",
    "                result = result.replace(\n",
    "                    \"{\" + placeholder + \"}\", str(variables[placeholder])\n",
    "                )\n",
    "\n",
    "        return result.replace(\"{{\", \"{\").replace(\"}}\", \"}\")\n",
    "\n",
    "    def generate_unique_ideas(\n",
    "        self, task_description, prompt_inputs_spec, num_cases\n",
    "    ):\n",
    "        \"\"\"Generate a list of unique ideas for test cases based on the task description\"\"\"\n",
    "\n",
    "        prompt = \"\"\"\n",
    "        Generate {num_cases} unique, diverse ideas for testing a prompt that accomplishes this task:\n",
    "        \n",
    "        <task_description>\n",
    "        {task_description}\n",
    "        </task_description>\n",
    "\n",
    "        The prompt will receive the following inputs\n",
    "        <prompt_inputs>\n",
    "        {prompt_inputs_spec}\n",
    "        </prompt_inputs>\n",
    "        \n",
    "        Each idea should represent a distinct scenario or example that tests different aspects of the task.\n",
    "        \n",
    "        Output Format:\n",
    "        Provide your response as a structured JSON array where each item is a brief description of the idea.\n",
    "        \n",
    "        Example:\n",
    "        ```json\n",
    "        [\n",
    "            \"Testing with technical computer science terminology\",\n",
    "            \"Testing with medical research findings\",\n",
    "            \"Testing with complex mathematical concepts\",\n",
    "            ...\n",
    "        ]\n",
    "        ```\n",
    "        \n",
    "        Ensure each idea is:\n",
    "        - Clearly distinct from the others\n",
    "        - Relevant to the task description\n",
    "        - Specific enough to guide generation of a full test case\n",
    "        - Quick to solve without requiring extensive computation or multi-step processing\n",
    "        - Solvable with no more than 400 tokens of output\n",
    "\n",
    "        Remember, only generate {num_cases} unique ideas\n",
    "        \"\"\"\n",
    "\n",
    "        system_prompt = \"You are a test scenario designer specialized in creating diverse, unique testing scenarios.\"\n",
    "\n",
    "        example_prompt_inputs = \"\"\n",
    "        for key, value in prompt_inputs_spec.items():\n",
    "            val = value.replace(\"\\n\", \"\\\\n\")\n",
    "            example_prompt_inputs += f'\"{key}\": str # {val},'\n",
    "\n",
    "        rendered_prompt = self.render(\n",
    "            dedent(prompt),\n",
    "            {\n",
    "                \"task_description\": task_description,\n",
    "                \"num_cases\": num_cases,\n",
    "                \"prompt_inputs\": example_prompt_inputs,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        messages = []\n",
    "        add_user_message(messages, rendered_prompt)\n",
    "        add_assistant_message(messages, \"```json\")\n",
    "        text = chat(\n",
    "            messages,\n",
    "            stop_sequences=[\"```\"],\n",
    "            system=system_prompt,\n",
    "            temperature=1.0,\n",
    "        )\n",
    "\n",
    "        return json.loads(text)\n",
    "\n",
    "    def generate_test_case(self, task_description, idea, prompt_inputs_spec={}):\n",
    "        \"\"\"Generate a single test case based on the task description and a specific idea\"\"\"\n",
    "\n",
    "        example_prompt_inputs = \"\"\n",
    "        for key, value in prompt_inputs_spec.items():\n",
    "            val = value.replace(\"\\n\", \"\\\\n\")\n",
    "            example_prompt_inputs += f'\"{key}\": \"EXAMPLE_VALUE\", // {val}\\n'\n",
    "\n",
    "        allowed_keys = \", \".join(\n",
    "            [f'\"{key}\"' for key in prompt_inputs_spec.keys()]\n",
    "        )\n",
    "\n",
    "        prompt = \"\"\"\n",
    "        Generate a single detailed test case for a prompt evaluation based on:\n",
    "        \n",
    "        <task_description>\n",
    "        {task_description}\n",
    "        </task_description>\n",
    "        \n",
    "        <specific_idea>\n",
    "        {idea}\n",
    "        </specific_idea>\n",
    "        \n",
    "        <allowed_input_keys>\n",
    "        {allowed_keys}\n",
    "        </allowed_input_keys>\n",
    "        \n",
    "        Output Format:\n",
    "        ```json\n",
    "        {{\n",
    "            \"prompt_inputs\": {{\n",
    "            {example_prompt_inputs}\n",
    "            }},\n",
    "            \"solution_criteria\": [\"criterion 1\", \"criterion 2\", ...] // Concise list of criteria for evaluating the solution, 1 to 4 items\n",
    "        }}\n",
    "        ```\n",
    "        \n",
    "        IMPORTANT REQUIREMENTS:\n",
    "        - You MUST ONLY use these exact input keys in your prompt_inputs: {allowed_keys}        \n",
    "        - Do NOT add any additional keys to prompt_inputs\n",
    "        - All keys listed in allowed_input_keys must be included in your response\n",
    "        - Make the test case realistic and practically useful\n",
    "        - Include measurable, concise solution criteria\n",
    "        - The solution criteria should ONLY address the direct requirements of the task description and the generated prompt_inputs\n",
    "        - Avoid over-specifying criteria with requirements that go beyond the core task\n",
    "        - Keep solution criteria simple, focused, and directly tied to the fundamental task\n",
    "        - The test case should be tailored to the specific idea provided\n",
    "        - Quick to solve without requiring extensive computation or multi-step processing\n",
    "        - Solvable with no more than 400 tokens of output\n",
    "        - DO NOT include any fields beyond those specified in the output format\n",
    "\n",
    "        Here's an example of a sample input with an ideal output:\n",
    "        <sample_input>\n",
    "        <sample_task_description>\n",
    "        Extract topics out of a passage of text\n",
    "        </sample_task_description>\n",
    "        <sample_specific_idea>\n",
    "        Testing with a text that contains multiple nested topics and subtopics (e.g., a passage about renewable energy that covers solar power economics, wind turbine technology, and policy implications simultaneously)\n",
    "        </sample_specific_idea>\n",
    "\n",
    "        <sample_allowed_input_keys>\n",
    "        \"content\"\n",
    "        </sample_allowed_input_keys>\n",
    "        </sample_input>\n",
    "        <ideal_output>\n",
    "        ```json\n",
    "        {\n",
    "            \"prompt_inputs\": {\n",
    "                \"content\": \"The transition to renewable energy encompasses numerous interdependent dimensions. Solar photovoltaic technology has seen dramatic cost reductions, with panel efficiency improving 24% since 2010 while manufacturing costs declined by 89%, making it economically competitive with fossil fuels in many markets. Concurrently, wind energy has evolved through innovative turbine designs featuring carbon-fiber composite blades and advanced control systems that increase energy capture by 35% in low-wind conditions.\"\n",
    "            },\n",
    "            \"solution_criteria\": [\n",
    "                \"Includes all topics mentioned\"   \n",
    "            ]\n",
    "        }\n",
    "        ```\n",
    "        </ideal_output>\n",
    "        This is ideal output because the solution criteria is concise and doesn't ask for anything outside of the scope of the task description.\n",
    "        \"\"\"\n",
    "\n",
    "        system_prompt = \"You are a test case creator specializing in designing evaluation scenarios.\"\n",
    "\n",
    "        rendered_prompt = self.render(\n",
    "            dedent(prompt),\n",
    "            {\n",
    "                \"allowed_keys\": allowed_keys,\n",
    "                \"task_description\": task_description,\n",
    "                \"idea\": idea,\n",
    "                \"example_prompt_inputs\": example_prompt_inputs,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        messages = []\n",
    "        add_user_message(messages, rendered_prompt)\n",
    "        add_assistant_message(messages, \"```json\")\n",
    "        text = chat(\n",
    "            messages,\n",
    "            stop_sequences=[\"```\"],\n",
    "            system=system_prompt,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "\n",
    "        test_case = json.loads(text)\n",
    "        test_case[\"task_description\"] = task_description\n",
    "        test_case[\"scenario\"] = idea\n",
    "\n",
    "        return test_case\n",
    "\n",
    "    def generate_dataset(\n",
    "        self,\n",
    "        task_description,\n",
    "        prompt_inputs_spec={},\n",
    "        num_cases=1,\n",
    "        output_file=\"dataset.json\",\n",
    "    ):\n",
    "        \"\"\"Generate test dataset based on task description and save to file\"\"\"\n",
    "        ideas = self.generate_unique_ideas(\n",
    "            task_description, prompt_inputs_spec, num_cases\n",
    "        )\n",
    "\n",
    "        dataset = []\n",
    "        completed = 0\n",
    "        total = len(ideas)\n",
    "        last_reported_percentage = 0\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(\n",
    "            max_workers=self.max_concurrent_tasks\n",
    "        ) as executor:\n",
    "            future_to_idea = {\n",
    "                executor.submit(\n",
    "                    self.generate_test_case,\n",
    "                    task_description,\n",
    "                    idea,\n",
    "                    prompt_inputs_spec,\n",
    "                ): idea\n",
    "                for idea in ideas\n",
    "            }\n",
    "\n",
    "            for future in concurrent.futures.as_completed(future_to_idea):\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    completed += 1\n",
    "                    current_percentage = int((completed / total) * 100)\n",
    "                    milestone_percentage = (current_percentage // 20) * 20\n",
    "\n",
    "                    if milestone_percentage > last_reported_percentage:\n",
    "                        print(f\"Generated {completed}/{total} test cases\")\n",
    "                        last_reported_percentage = milestone_percentage\n",
    "\n",
    "                    dataset.append(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating test case: {e}\")\n",
    "\n",
    "        with open(output_file, \"w\") as f:\n",
    "            json.dump(dataset, f, indent=2)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def grade_output(self, test_case, output, extra_criteria):\n",
    "        \"\"\"Grade the output of a test case using the model\"\"\"\n",
    "\n",
    "        prompt_inputs = \"\"\n",
    "        for key, value in test_case[\"prompt_inputs\"].items():\n",
    "            val = value.replace(\"\\n\", \"\\\\n\")\n",
    "            prompt_inputs += f'\"{key}\":\"{val}\",\\n'\n",
    "\n",
    "        extra_criteria_section = \"\"\n",
    "        if extra_criteria:\n",
    "            extra_criteria_template = \"\"\"\n",
    "            Mandatory Requirements - ANY VIOLATION MEANS AUTOMATIC FAILURE (score of 3 or lower):\n",
    "            <extra_important_criteria>\n",
    "            {extra_criteria}\n",
    "            </extra_important_criteria>\n",
    "            \"\"\"\n",
    "            extra_criteria_section = self.render(\n",
    "                dedent(extra_criteria_template),\n",
    "                {\"extra_criteria\": extra_criteria},\n",
    "            )\n",
    "\n",
    "        eval_template = \"\"\"\n",
    "        Your task is to evaluate the following AI-generated solution with EXTREME RIGOR.\n",
    "\n",
    "        Original task description:\n",
    "        <task_description>\n",
    "        {task_description}\n",
    "        </task_description>\n",
    "\n",
    "        Original task inputs:\n",
    "        <task_inputs>\n",
    "        {{ {prompt_inputs} }}\n",
    "        </task_inputs>\n",
    "\n",
    "        Solution to Evaluate:\n",
    "        <solution>\n",
    "        {output}\n",
    "        </solution>\n",
    "\n",
    "        Criteria you should use to evaluate the solution:\n",
    "        <criteria>\n",
    "        {solution_criteria}\n",
    "        </criteria>\n",
    "\n",
    "        {extra_criteria_section}\n",
    "\n",
    "        Scoring Guidelines:\n",
    "        * Score 1-3: Solution fails to meet one or more MANDATORY requirements\n",
    "        * Score 4-6: Solution meets all mandatory requirements but has significant deficiencies in secondary criteria\n",
    "        * Score 7-8: Solution meets all mandatory requirements and most secondary criteria, with minor issues\n",
    "        * Score 9-10: Solution meets all mandatory and secondary criteria\n",
    "\n",
    "        IMPORTANT SCORING INSTRUCTIONS:\n",
    "        * Grade the output based ONLY on the listed criteria. Do not add your own extra requirements.\n",
    "        * If a solution meets all of the mandatory and secondary criteria give it a 10\n",
    "        * Don't complain that the solution \"only\" meets the mandatory and secondary criteria. Solutions shouldn't go above and beyond - they should meet the exact listed criteria.\n",
    "        * ANY violation of a mandatory requirement MUST result in a score of 3 or lower\n",
    "        * The full 1-10 scale should be utilized - don't hesitate to give low scores when warranted\n",
    "\n",
    "        Output Format\n",
    "        Provide your evaluation as a structured JSON object with the following fields, in this specific order:\n",
    "        - \"strengths\": An array of 1-3 key strengths\n",
    "        - \"weaknesses\": An array of 1-3 key areas for improvement\n",
    "        - \"reasoning\": A concise explanation of your overall assessment\n",
    "        - \"score\": A number between 1-10\n",
    "\n",
    "        Respond with JSON. Keep your response concise and direct.\n",
    "        Example response shape:\n",
    "        {{\n",
    "            \"strengths\": string[],\n",
    "            \"weaknesses\": string[],\n",
    "            \"reasoning\": string,\n",
    "            \"score\": number\n",
    "        }}\n",
    "        \"\"\"\n",
    "\n",
    "        eval_prompt = self.render(\n",
    "            dedent(eval_template),\n",
    "            {\n",
    "                \"task_description\": test_case[\"task_description\"],\n",
    "                \"prompt_inputs\": prompt_inputs,\n",
    "                \"output\": output,\n",
    "                \"solution_criteria\": \"\\n\".join(test_case[\"solution_criteria\"]),\n",
    "                \"extra_criteria_section\": extra_criteria_section,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        messages = []\n",
    "        add_user_message(messages, eval_prompt)\n",
    "        add_assistant_message(messages, \"```json\")\n",
    "        eval_text = chat(\n",
    "            messages,\n",
    "            stop_sequences=[\"```\"],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        return json.loads(eval_text)\n",
    "\n",
    "    def run_test_case(\n",
    "        self, test_case, run_prompt_function, extra_criteria=None\n",
    "    ):\n",
    "        \"\"\"Run a test case and grade the result\"\"\"\n",
    "        output = run_prompt_function(test_case[\"prompt_inputs\"])\n",
    "\n",
    "        model_grade = self.grade_output(test_case, output, extra_criteria)\n",
    "        model_score = model_grade[\"score\"]\n",
    "        reasoning = model_grade[\"reasoning\"]\n",
    "\n",
    "        return {\n",
    "            \"output\": output,\n",
    "            \"test_case\": test_case,\n",
    "            \"score\": model_score,\n",
    "            \"reasoning\": reasoning,\n",
    "        }\n",
    "\n",
    "    def run_evaluation(\n",
    "        self,\n",
    "        run_prompt_function,\n",
    "        dataset_file,\n",
    "        extra_criteria=None,\n",
    "        json_output_file=\"output.json\",\n",
    "        html_output_file=\"output.html\",\n",
    "    ):\n",
    "        \"\"\"Run evaluation on all test cases in the dataset\"\"\"\n",
    "        with open(dataset_file, \"r\") as f:\n",
    "            dataset = json.load(f)\n",
    "\n",
    "        results = []\n",
    "        completed = 0\n",
    "        total = len(dataset)\n",
    "        last_reported_percentage = 0\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(\n",
    "            max_workers=self.max_concurrent_tasks\n",
    "        ) as executor:\n",
    "            future_to_test_case = {\n",
    "                executor.submit(\n",
    "                    self.run_test_case,\n",
    "                    test_case,\n",
    "                    run_prompt_function,\n",
    "                    extra_criteria,\n",
    "                ): test_case\n",
    "                for test_case in dataset\n",
    "            }\n",
    "\n",
    "            for future in concurrent.futures.as_completed(future_to_test_case):\n",
    "                result = future.result()\n",
    "                completed += 1\n",
    "                current_percentage = int((completed / total) * 100)\n",
    "                milestone_percentage = (current_percentage // 20) * 20\n",
    "\n",
    "                if milestone_percentage > last_reported_percentage:\n",
    "                    print(f\"Graded {completed}/{total} test cases\")\n",
    "                    last_reported_percentage = milestone_percentage\n",
    "                results.append(result)\n",
    "\n",
    "        average_score = mean([result[\"score\"] for result in results])\n",
    "        print(f\"Average score: {average_score}\")\n",
    "\n",
    "        with open(json_output_file, \"w\") as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "\n",
    "        html = generate_prompt_evaluation_report(results)\n",
    "        with open(html_output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(html)\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of PromptEvaluator\n",
    "# Increase `max_concurrent_tasks` for greater concurrency, but beware of rate limit errors!\n",
    "evaluator = PromptEvaluator(max_concurrent_tasks=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and run the prompt to be evaluated, returning the raw model output\n",
    "# This function is executed once for each test case.\n",
    "def run_prompt(prompt_inputs):\n",
    "   prompt = f\"\"\"\n",
    "   This is a paragraph of a scholarly article\n",
    "   Search the paragraph for topics.\n",
    "   Refine search for subtopics.\n",
    "   Check for metaphor or text as code.\n",
    "   Make sure elements are semantically orthogonal.\n",
    "   Use the topic to create a JSON array of strings.\n",
    "   Ensure the strings are concise, explicative, and relevant.\n",
    "   Do not add any comments or extra text.\n",
    "   {prompt_inputs[\"content\"]}\n",
    "   \"\"\"\n",
    "\n",
    "   messages = []\n",
    "   add_user_message(messages, prompt)\n",
    "   return chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[\n",
      "    \"Scientific article from social psychology exploring human behavior, testing topic extraction with qualitative research terminology\",\n",
      "    \"Environmental science research passage discussing climate change impacts, with interdisciplinary technical vocabulary\",\n",
      "    \"Neuroscience journal excerpt about brain plasticity, requiring nuanced topic identification across complex scientific language\",\n",
      "    \"Comparative literature analysis text exploring postmodern narrative techniques, testing topic extraction in humanities scholarship\"\n",
      "]\n",
      "\n",
      "{\n",
      "{\n",
      "    \"prompt_inputs\": {\n",
      "        \"content\": \"Social conformity represents a critical mechanism\n",
      "    \"prompt_ ininputs\": {\n",
      "        \"content\": \"Recent climate change research reveals complex understanding group interactions between oceanic carbon dynamics sequ anestration and individuald atmospheric greenhouse behavioral gas dynamics adaptation. Marine ecos. Through extensiveystems play qual a critical role in globalitative research, psychologists have observe carbon cycles, withd that participants ph frequently modifyytoplankton absorbing approximately 20 their expresse-d beliefs25 and actions to align% of anthropogenic carbon with perceived group dioxide emissions annually. Emerging norms, satellite monitoring even when those modifications contra technologies andict their personal initial perspectives. The phenomenond advanced computational models now enable, researchers to track these first intr systematically documented by Solomon Asch in his landmark conformicate bioity experiments, reveals complex psychologicalgeochemical processes with processes unprecedented spatial and temporal resolution, highlighting of the interconnecte social influence and normative pressure.\"d nature of climate system feedback mechanisms\n",
      "    },\n",
      "    \"solution_criteria\": [\n",
      "        \"Accurately extract.\"\n",
      "    }, \n",
      "    \"solution_criteria3\": [\n",
      "        \"Correctly- identify 5 primary3-5 topics from the scholarly text distinct\",\n",
      "        \"Represent topics topics from the passage as\",\n",
      "        \"Represent topics as a vali a valid JSON array of strings\",d JSON array of strings\",\n",
      "        \"Capture core th\n",
      "        \"Capture core conceptematic elementsual themes without without verb excessiveatim text copying detail\"\n",
      "    ]\n",
      "}\n",
      "Generated 1/4 test cases\n",
      "\"\n",
      "    ]\n",
      "}\n",
      "Generated 2/4 test cases\n",
      "\n",
      "{\n",
      "{\n",
      "    \"prompt_inputs\": {\n",
      "        \"content\": \"Neural plasticity represents a\n",
      "    \"prompt_inputs\": {\n",
      "        \"content\": \"In contemporary comparative literature, post fundamental mechanism ofmodern narrative techniques challenge traditional linear brain adaptation, storyt whereinelling by sy fragmenting chronology and destnaptic connections dynamically reorganize inabilizing narrative perspective response to experience, learning, and neurological. Authors like challenges Thomas. Researchers have discovered that specific neural Pynchon an networks demonstrated It remarkable capacityalo Calvino employ met for structural and functional recafictional strategies that blur boundariesonfiguration, particularly in regions between reality and fiction, associate creating recursive textd with memory consolidation anual landscapesd motor where skill nar acquisitionration becomes. These a self adaptive processes-reflexive exploration involve of literary construction and epis complex molecular signtemologicalaling casc uncertainty.\"ades, including neurotrophic factor expression an\n",
      "    },\n",
      "    d synaptic protein modifications\"solution_criteria\": that enable [\n",
      "        \"Accurately neurons identify to modify core conceptual topics\",\n",
      "        \"Capture their connectivity scholarly patterns terminology and computational capabilities and key themes.\"\",\n",
      "        \"Produce a JSON array representing extracte\n",
      "    },\n",
      "    \"solution_criteria\":d topics\"\n",
      "    ] [\n",
      "        \"Accurately extract\n",
      "}\n",
      " coreGenerated 3/4 test cases\n",
      " scientific topics from the passage\",\n",
      "        \"Capture both broad and specific neuroscience concepts\",\n",
      "        \"Represent topics as a valid JSON array of strings\"\n",
      "    ]\n",
      "}\n",
      "Generated 4/4 test cases\n"
     ]
    }
   ],
   "source": [
    "dataset = evaluator.generate_dataset(\n",
    "    # Describe the purpose or goal of the prompt you're trying to test\n",
    "    task_description=\"\"\"\n",
    "    Extract topics out of a passage of text from a scholarly article into a JSON array of strings.\n",
    "    \"\"\",\n",
    "    # Describe the different inputs that your prompt requires\n",
    "    prompt_inputs_spec={\n",
    "        \"content\": \"One paragraph of text from a scholarly journal written in English\"\n",
    "    },\n",
    "    # Where to write the generated dataset\n",
    "    output_file=\"dataset.json\",\n",
    "    # Number of test cases to generate (recommend keeping this low if you're getting rate limit errors)\n",
    "    num_cases=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\n",
      "    \"\n",
      "    Social\"Climate Change Conformity\", Research\",\n",
      "    \"Carbon Sequestration\",\n",
      "    \"Marine Ecosystem\n",
      "    \"Group Dynamics\",\n",
      "    \"Behavioral Adaptation\",\n",
      "    \"Normative Influence\",\n",
      "    \"Psychological Modification Dynamics\",\n",
      "    \"Phytoplankton Carbon Absorption\",\n",
      "    \"Greenhouse Gas Interactions\",\n",
      "    \"Solomon Asch Experiments\",\n",
      "    \"Satellite Environmental\",\n",
      "    \"Qualitative Research Methodology Monitoring\",\n",
      "    \"Computational Climate\",\n",
      "    \"Individual Perspective Modeling\", Alt\n",
      "    \"Bioeration\"geochemical Process Tracking\"\n",
      "]\n",
      "]\n",
      "{\n",
      "    \"streng\n",
      "{\n",
      "    \"strengths\": [\n",
      "        \"Captures key thths\": [\n",
      "        \"Capturesematic elements from key conceptual themes from the text the passage\",\n",
      "        \"Represents topics as a valid JSON array of\",\n",
      "        \"Provides strings\",\n",
      "        \"Provides a valid JSON array of topic a balanced set strings\",\n",
      "        \"Av of 8oids verbatim text distinct topics\" copying\"\n",
      "    ],\n",
      "    ],\n",
      "    \"\n",
      "    \"weaknessesweaknesses\": [\": [\n",
      "        \"\n",
      "        \"SlightlySlightly exce overeds recommended -extracts topics (73-5 topic range\",\n",
      "        \"Some topics topics instead of recommended 3-5)\", are somewhat\n",
      "        \"Some overl topics are somewhat granapping (ular/e.g. 'specific\"Computational\n",
      "    ],\n",
      "     Climate Modeling' an\"reasoning\": \"The solution successfullyd 'Bioge meetsochemical Process Tracking')\" all mandatory requirements and most secondary criteria. The\n",
      "    ],\n",
      "     topics are\"reasoning\": \"The concept solution successfully extracts meaningful topics from the scholarly textually relevant to, meeting all the text, represente mandatory requirements. While the numberd as a clean JSON array, and avoid direct of topics is slightly higher text than recommended, each topic is clearly derive copying.d from the source The material an only minord represents a distinct aspect issues of the research discusse are the slightly excessived.\",\n",
      "    \"score number of topics an\": 9d some granul\n",
      "}arity in\n",
      " topic specifGraded 1/4 test cases\n",
      "icity.\",\n",
      "    \"score\": 9\n",
      "}\n",
      "Graded 2/4 test cases\n",
      "[\n",
      "    \"Postmodern Narrative Techniques\",\n",
      "    \"Non-linear Storytelling\",\n",
      "    \"Narrative Perspective Destabilization\",\n",
      "    \"Metafictional Strategies\",\n",
      "    \"Reality-Fiction Boundary Dissolution\",\n",
      "    \"Textual Self-Reflexivity\",\n",
      "    \"Epistemological Uncertainty\",\n",
      "    \"Comparative Literature Analysis\"\n",
      "][\n",
      "    \n",
      "{\n",
      "    \"streng\"Neural Plasticity\",\n",
      "    ths\": [\n",
      "        \"\"Comprehensive coverageSy of key scholarlynaptic Reorgan concepts\",\n",
      "        \"ization\",\n",
      "    \"Precise extraction of abstractBrain Adaptation literary Mechanisms\",\n",
      "    \"Experience- themes\",\n",
      "        \"WellDependent Neur-formatteoplasticity\",d JSON\n",
      "    \"Neural Network Reconfiguration\",\n",
      "     array output\"\n",
      "    \"Memory Consolidation\",],\n",
      "    \"weak\n",
      "    \"Motor Skill Learningnesses\": [\n",
      "        \"Slight\",\n",
      "    \" potentialMolecular for over-abst Signaling Cascraction of topicsades\",\n",
      "    \"Neurotrophic\",\n",
      "        \"Minor redun Factor Expression\",\n",
      "    \"Synaptic Protein Modification\"dancy in some topic descriptions\n",
      "]\"\n",
      "    ],\n",
      "    \"reasoning\": \"The solution successfully extracts scholarly topics from the passage, capturing the core postmodern literary concepts\n",
      "{\n",
      "    \"streng with academicths\": [\n",
      "        \" precision. AllComprehensive mandatory coverage of neuroscience requirements are met, including JSON array topics\",\n",
      "        \"Captures format, both broad and specific concepts from the passage topic specificity, and absence\",\n",
      "        \"Vali of exd JSON array format\"\n",
      "    ],traneous commentary.\",\n",
      "    \"weaknesses\":\n",
      "    \"score\": [\n",
      "        \"Some topics are 9\n",
      "} slightly\n",
      " redundant (e.g.,Graded 3/4 test cases\n",
      " 'Neural Plasticity' and 'Brain Adaptation Mechanisms')\",\n",
      "        \"Slight over-extraction of topics beyond core themes\"\n",
      "    ],\n",
      "    \"reasoning\": \"The solution successfully extracts scientific topics from the passage, representing the key neuroscience concepts with precision. It meets all mandatory requirements by providing a clean JSON array of topic strings that accurately reflect the text's content. While there are minor nuances in topic selection, the overall extraction is robust and scientifically sound.\",\n",
      "    \"score\": 9\n",
      "}\n",
      "Graded 4/4 test cases\n",
      "Average score: 9\n"
     ]
    }
   ],
   "source": [
    "results = evaluator.run_evaluation(\n",
    "    run_prompt_function=run_prompt,\n",
    "    dataset_file=\"dataset.json\",\n",
    "    extra_criteria=\"\"\"\n",
    "    - Contains a JSON array of strings, containing each topic mentioned in the article.\n",
    "    - The strings should contain only a topic without any extra commentary\n",
    "    - Response should contain the JSON array and nothing else\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    <!DOCTYPE html>\\n    <html lang=\"en\">\\n    <head>\\n        <meta charset=\"UTF-8\">\\n        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\\n        <title>Prompt Evaluation Report</title>\\n        <style>\\n            body {\\n                font-family: Arial, sans-serif;\\n                line-height: 1.6;\\n                margin: 0;\\n                padding: 20px;\\n                color: #333;\\n            }\\n            .header {\\n                background-color: #f0f0f0;\\n                padding: 20px;\\n                border-radius: 5px;\\n                margin-bottom: 20px;\\n            }\\n            .summary-stats {\\n                display: flex;\\n                justify-content: space-between;\\n                flex-wrap: wrap;\\n                gap: 10px;\\n            }\\n            .stat-box {\\n                background-color: #fff;\\n                border-radius: 5px;\\n                padding: 15px;\\n                box-shadow: 0 2px 5px rgba(0,0,0,0.1);\\n                flex-basis: 30%;\\n                min-width: 200px;\\n            }\\n            .stat-value {\\n                font-size: 24px;\\n                font-weight: bold;\\n                margin-top: 5px;\\n            }\\n            table {\\n                width: 100%;\\n                border-collapse: collapse;\\n                margin-top: 20px;\\n            }\\n            th {\\n                background-color: #4a4a4a;\\n                color: white;\\n                text-align: left;\\n                padding: 12px;\\n            }\\n            td {\\n                padding: 10px;\\n                border-bottom: 1px solid #ddd;\\n                vertical-align: top;\\n            }\\n            tr:nth-child(even) {\\n                background-color: #f9f9f9;\\n            }\\n            .output-cell {\\n                white-space: pre-wrap;\\n            }\\n            .score {\\n                font-weight: bold;\\n                padding: 5px 10px;\\n                border-radius: 3px;\\n                display: inline-block;\\n            }\\n            .score-high {\\n                background-color: #c8e6c9;\\n                color: #2e7d32;\\n            }\\n            .score-medium {\\n                background-color: #fff9c4;\\n                color: #f57f17;\\n            }\\n            .score-low {\\n                background-color: #ffcdd2;\\n                color: #c62828;\\n            }\\n            .output {\\n                overflow: auto;\\n                white-space: pre-wrap;\\n            }\\n\\n            .output pre {\\n                background-color: #f5f5f5;\\n                border: 1px solid #ddd;\\n                border-radius: 4px;\\n                padding: 10px;\\n                margin: 0;\\n                font-family: \\'Consolas\\', \\'Monaco\\', \\'Courier New\\', monospace;\\n                font-size: 14px;\\n                line-height: 1.4;\\n                color: #333;\\n                box-shadow: inset 0 1px 3px rgba(0, 0, 0, 0.1);\\n                overflow-x: auto;\\n                white-space: pre-wrap; \\n                word-wrap: break-word; \\n            }\\n\\n            td {\\n                width: 20%;\\n            }\\n            .score-col {\\n                width: 80px;\\n            }\\n        </style>\\n    </head>\\n    <body>\\n        <div class=\"header\">\\n            <h1>Prompt Evaluation Report</h1>\\n            <div class=\"summary-stats\">\\n                <div class=\"stat-box\">\\n                    <div>Total Test Cases</div>\\n                    <div class=\"stat-value\">4</div>\\n                </div>\\n                <div class=\"stat-box\">\\n                    <div>Average Score</div>\\n                    <div class=\"stat-value\">9.0 / 10</div>\\n                </div>\\n                <div class=\"stat-box\">\\n                    <div>Pass Rate (≥7)</div>\\n                    <div class=\"stat-value\">100.0%</div>\\n                </div>\\n            </div>\\n        </div>\\n\\n        <table>\\n            <thead>\\n                <tr>\\n                    <th>Scenario</th>\\n                    <th>Prompt Inputs</th>\\n                    <th>Solution Criteria</th>\\n                    <th>Output</th>\\n                    <th>Score</th>\\n                    <th>Reasoning</th>\\n                </tr>\\n            </thead>\\n            <tbody>\\n    \\n            <tr>\\n                <td>Environmental science research passage discussing climate change impacts, with interdisciplinary technical vocabulary</td>\\n                <td class=\"prompt-inputs\"><strong>content:</strong> Recent climate change research reveals complex interactions between oceanic carbon sequestration and atmospheric greenhouse gas dynamics. Marine ecosystems play a critical role in global carbon cycles, with phytoplankton absorbing approximately 20-25% of anthropogenic carbon dioxide emissions annually. Emerging satellite monitoring technologies and advanced computational models now enable researchers to track these intricate biogeochemical processes with unprecedented spatial and temporal resolution, highlighting the interconnected nature of climate system feedback mechanisms.</td>\\n                <td class=\"criteria\">• Correctly identify 3-5 distinct topics from the passage<br>• Represent topics as a valid JSON array of strings<br>• Capture core thematic elements without excessive detail</td>\\n                <td class=\"output\"><pre>[\\n    \"Climate Change Research\",\\n    \"Carbon Sequestration\",\\n    \"Marine Ecosystem Dynamics\",\\n    \"Phytoplankton Carbon Absorption\",\\n    \"Greenhouse Gas Interactions\",\\n    \"Satellite Environmental Monitoring\",\\n    \"Computational Climate Modeling\",\\n    \"Biogeochemical Process Tracking\"\\n]</pre></td>\\n                <td class=\"score-col\"><span class=\"score score-high\">9</span></td>\\n                <td class=\"reasoning\">The solution successfully extracts meaningful topics from the scholarly text, meeting all mandatory requirements. While the number of topics is slightly higher than recommended, each topic is clearly derived from the source material and represents a distinct aspect of the research discussed.</td>\\n            </tr>\\n        \\n            <tr>\\n                <td>Scientific article from social psychology exploring human behavior, testing topic extraction with qualitative research terminology</td>\\n                <td class=\"prompt-inputs\"><strong>content:</strong> Social conformity represents a critical mechanism in understanding group dynamics and individual behavioral adaptation. Through extensive qualitative research, psychologists have observed that participants frequently modify their expressed beliefs and actions to align with perceived group norms, even when those modifications contradict their personal initial perspectives. The phenomenon, first systematically documented by Solomon Asch in his landmark conformity experiments, reveals complex psychological processes of social influence and normative pressure.</td>\\n                <td class=\"criteria\">• Accurately extract 3-5 primary topics from the scholarly text<br>• Represent topics as a valid JSON array of strings<br>• Capture core conceptual themes without verbatim text copying</td>\\n                <td class=\"output\"><pre>[\\n    \"Social Conformity\",\\n    \"Group Dynamics\",\\n    \"Behavioral Adaptation\",\\n    \"Normative Influence\",\\n    \"Psychological Modification\",\\n    \"Solomon Asch Experiments\",\\n    \"Qualitative Research Methodology\",\\n    \"Individual Perspective Alteration\"\\n]</pre></td>\\n                <td class=\"score-col\"><span class=\"score score-high\">9</span></td>\\n                <td class=\"reasoning\">The solution successfully meets all mandatory requirements and most secondary criteria. The topics are conceptually relevant to the text, represented as a clean JSON array, and avoid direct text copying. The only minor issues are the slightly excessive number of topics and some granularity in topic specificity.</td>\\n            </tr>\\n        \\n            <tr>\\n                <td>Comparative literature analysis text exploring postmodern narrative techniques, testing topic extraction in humanities scholarship</td>\\n                <td class=\"prompt-inputs\"><strong>content:</strong> In contemporary comparative literature, postmodern narrative techniques challenge traditional linear storytelling by fragmenting chronology and destabilizing narrative perspective. Authors like Thomas Pynchon and Italo Calvino employ metafictional strategies that blur boundaries between reality and fiction, creating recursive textual landscapes where narration becomes a self-reflexive exploration of literary construction and epistemological uncertainty.</td>\\n                <td class=\"criteria\">• Accurately identify core conceptual topics<br>• Capture scholarly terminology and key themes<br>• Produce a JSON array representing extracted topics</td>\\n                <td class=\"output\"><pre>[\\n    \"Postmodern Narrative Techniques\",\\n    \"Non-linear Storytelling\",\\n    \"Narrative Perspective Destabilization\",\\n    \"Metafictional Strategies\",\\n    \"Reality-Fiction Boundary Dissolution\",\\n    \"Textual Self-Reflexivity\",\\n    \"Epistemological Uncertainty\",\\n    \"Comparative Literature Analysis\"\\n]</pre></td>\\n                <td class=\"score-col\"><span class=\"score score-high\">9</span></td>\\n                <td class=\"reasoning\">The solution successfully extracts scholarly topics from the passage, capturing the core postmodern literary concepts with academic precision. All mandatory requirements are met, including JSON array format, topic specificity, and absence of extraneous commentary.</td>\\n            </tr>\\n        \\n            <tr>\\n                <td>Neuroscience journal excerpt about brain plasticity, requiring nuanced topic identification across complex scientific language</td>\\n                <td class=\"prompt-inputs\"><strong>content:</strong> Neural plasticity represents a fundamental mechanism of brain adaptation, wherein synaptic connections dynamically reorganize in response to experience, learning, and neurological challenges. Researchers have discovered that specific neural networks demonstrate remarkable capacity for structural and functional reconfiguration, particularly in regions associated with memory consolidation and motor skill acquisition. These adaptive processes involve complex molecular signaling cascades, including neurotrophic factor expression and synaptic protein modifications that enable neurons to modify their connectivity patterns and computational capabilities.</td>\\n                <td class=\"criteria\">• Accurately extract core scientific topics from the passage<br>• Capture both broad and specific neuroscience concepts<br>• Represent topics as a valid JSON array of strings</td>\\n                <td class=\"output\"><pre>[\\n    \"Neural Plasticity\",\\n    \"Synaptic Reorganization\",\\n    \"Brain Adaptation Mechanisms\",\\n    \"Experience-Dependent Neuroplasticity\",\\n    \"Neural Network Reconfiguration\",\\n    \"Memory Consolidation\",\\n    \"Motor Skill Learning\",\\n    \"Molecular Signaling Cascades\",\\n    \"Neurotrophic Factor Expression\",\\n    \"Synaptic Protein Modification\"\\n]</pre></td>\\n                <td class=\"score-col\"><span class=\"score score-high\">9</span></td>\\n                <td class=\"reasoning\">The solution successfully extracts scientific topics from the passage, representing the key neuroscience concepts with precision. It meets all mandatory requirements by providing a clean JSON array of topic strings that accurately reflect the text\\'s content. While there are minor nuances in topic selection, the overall extraction is robust and scientifically sound.</td>\\n            </tr>\\n        \\n            </tbody>\\n        </table>\\n    </body>\\n    </html>\\n    '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_output_file = \"output.json\"\n",
    "html_output_file = \"output.html\"\n",
    "with open(json_output_file, \"w\") as f:\n",
    "   json.dump(results, f, indent=2)\n",
    "\n",
    "html = generate_prompt_evaluation_report(results)\n",
    "with open(html_output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "   f.write(html)\n",
    "generate_prompt_evaluation_report(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
