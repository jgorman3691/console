{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f18d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import voyageai\n",
    "import re\n",
    "import math\n",
    "from typing import Optional, Any, List, Dict, Tuple\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "load_dotenv()\n",
    "client = voyageai.Client()\n",
    "console = Path(\"/home/jx-creator/Projects/console\")\n",
    "tutorials = console / \"tutorials\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cae2a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk by a set number of characters\n",
    "def chunk_by_char(text, chunk_size=300, overlap=30):\n",
    "   chunks: list = []\n",
    "   start_index: int = 0\n",
    "   text_length = len(text)\n",
    "\n",
    "   while start_index < text_length:\n",
    "      end_index: int = min(start_index + chunk_size, text_length)\n",
    "\n",
    "      chunk_text = text[start_index:end_index]\n",
    "      chunks.append(chunk_text)\n",
    "\n",
    "      start_index: int = (\n",
    "         end_index - overlap if end_index < text_length else text_length\n",
    "      )\n",
    "\n",
    "   return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cc0d549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk by sentence\n",
    "def chunk_by_sentence(text, max_per_chunk=5, overlap=1):\n",
    "   sentences = re.split(r\"(?<=[.!?])\\s+\", text)\n",
    "\n",
    "   chunks: list = []\n",
    "   start: int = 0\n",
    "   length: int = len(sentences)\n",
    "\n",
    "   while start < length:\n",
    "      end: int = min(start + max_per_chunk, length)\n",
    "\n",
    "      current = sentences[start:end]\n",
    "      chunks.append(\" \".join(current))\n",
    "\n",
    "      start += max_per_chunk - overlap\n",
    "\n",
    "      if start < 0:\n",
    "         start = 0\n",
    "   \n",
    "   return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff3ee6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk by section\n",
    "def chunk_by_section(document):\n",
    "   pattern = r\"\\n## \"\n",
    "   return re.split(pattern, document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6b33e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tutorials / \"rag\" / \"report.md\", \"r\") as f:\n",
    "   text = f.read()\n",
    "\n",
    "chunks = chunk_by_section(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95289381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Table of Contents\\n\\n1.  Executive Summary\\n2.  Table of Contents\\n3.  Methodology\\n4.  Section 1: Medical Research - Understanding XDR-471 Syndrome\\n5.  Section 2: Software Engineering - Project Phoenix Stability Enhancements\\n6.  Section 3: Financial Analysis - Q3 Performance and Outlook\\n7.  Section 4: Scientific Experimentation - Characterization of Material Composite XT-5\\n8.  Section 5: Legal Developments - Navigating IP Precedents and Regulatory Shifts\\n9.  Section 6: Product Engineering - Finalizing Model Zircon-5 Specifications\\n10. Section 7: Historical Research - Re-evaluating the Galveston Accords (1921)\\n11. Section 8: Project Management - Progress on Project Cerberus Phase 2B\\n12. Section 9: Pharmaceutical Development - Compound CTX-204b Phase IIa Update\\n13. Section 10: Cybersecurity Analysis - Incident Response Report\\n14. Future Directions\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15d1ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(chunks, model=\"voyage-3-large\", input_type=\"query\"):\n",
    "   is_list: bool = isinstance(chunks, list)\n",
    "   input: list = chunks if is_list else [chunks]\n",
    "   result = client.embed(input, model=model, input_type=input_type)\n",
    "   return result.embeddings if is_list else result.embeddings[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba978fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class VectorIndex:\n",
    "#   def __init__(\n",
    "#         self,\n",
    "#         distance_metric: str = \"cosine\",\n",
    "#         embedding_fn=None,\n",
    "#   ):\n",
    "#      self.vectors: List[List[float]] = []\n",
    "#      self.documents: List[Dict[str, Any]] = []\n",
    "#      self.vec_dim: Optional[int] = None\n",
    "#      if distance_metric not in [\"cosine\", \"euclidian\"]:\n",
    "#         raise ValueError(\"distance_metric must be one of either 'cosine' or 'euclidean'\")\n",
    "#      self.metric: str = distance_metric\n",
    "#      self.embedding = embedding_fn\n",
    "#   \n",
    "#   def add_document(self, document: Dict[str, Any]):\n",
    "#      if not self.embedding:\n",
    "#         raise ValueError(\n",
    "#            \"The embedding function was not provided during initialization.\"\n",
    "#         )\n",
    "#      if not isinstance(document, dict):\n",
    "#         raise TypeError(\"Document must be a dictionary\")\n",
    "#      if \"content\" not in document:\n",
    "#         raise ValueError(\"The document dictionary must contain a 'content' key.\")\n",
    "#      \n",
    "#      content = document[\"content\"]\n",
    "#      if not isinstance(content, str):\n",
    "#         raise TypeError(\"Document 'content' must be a string.\")\n",
    "#      \n",
    "#      vector = self.embedding(content)\n",
    "#      self.add_vector(vector=vector, document=document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "644abfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VectorIndex implementation\n",
    "import math\n",
    "from typing import Optional, Any, List, Dict, Tuple\n",
    "\n",
    "\n",
    "class VectorIndex:\n",
    "    def __init__(\n",
    "        self,\n",
    "        distance_metric: str = \"cosine\",\n",
    "        embedding_fn=None,\n",
    "    ):\n",
    "        self.vectors: List[List[float]] = []\n",
    "        self.documents: List[Dict[str, Any]] = []\n",
    "        self._vector_dim: Optional[int] = None\n",
    "        if distance_metric not in [\"cosine\", \"euclidean\"]:\n",
    "            raise ValueError(\"distance_metric must be 'cosine' or 'euclidean'\")\n",
    "        self._distance_metric = distance_metric\n",
    "        self._embedding_fn = embedding_fn\n",
    "\n",
    "    def add_document(self, document: Dict[str, Any]):\n",
    "        if not self._embedding_fn:\n",
    "            raise ValueError(\n",
    "                \"Embedding function not provided during initialization.\"\n",
    "            )\n",
    "        if not isinstance(document, dict):\n",
    "            raise TypeError(\"Document must be a dictionary.\")\n",
    "        if \"content\" not in document:\n",
    "            raise ValueError(\n",
    "                \"Document dictionary must contain a 'content' key.\"\n",
    "            )\n",
    "\n",
    "        content = document[\"content\"]\n",
    "        if not isinstance(content, str):\n",
    "            raise TypeError(\"Document 'content' must be a string.\")\n",
    "\n",
    "        vector = self._embedding_fn(content)\n",
    "        self.add_vector(vector=vector, document=document)\n",
    "\n",
    "    def search(\n",
    "        self, query: Any, k: int = 1\n",
    "    ) -> List[Tuple[Dict[str, Any], float]]:\n",
    "        if not self.vectors:\n",
    "            return []\n",
    "\n",
    "        if isinstance(query, str):\n",
    "            if not self._embedding_fn:\n",
    "                raise ValueError(\n",
    "                    \"Embedding function not provided for string query.\"\n",
    "                )\n",
    "            query_vector = self._embedding_fn(query)\n",
    "        elif isinstance(query, list) and all(\n",
    "            isinstance(x, (int, float)) for x in query\n",
    "        ):\n",
    "            query_vector = query\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                \"Query must be either a string or a list of numbers.\"\n",
    "            )\n",
    "\n",
    "        if self._vector_dim is None:\n",
    "            return []\n",
    "\n",
    "        if len(query_vector) != self._vector_dim:\n",
    "            raise ValueError(\n",
    "                f\"Query vector dimension mismatch. Expected {self._vector_dim}, got {len(query_vector)}\"\n",
    "            )\n",
    "\n",
    "        if k <= 0:\n",
    "            raise ValueError(\"k must be a positive integer.\")\n",
    "\n",
    "        if self._distance_metric == \"cosine\":\n",
    "            dist_func = self._cosine_distance\n",
    "        else:\n",
    "            dist_func = self._euclidean_distance\n",
    "\n",
    "        distances = []\n",
    "        for i, stored_vector in enumerate(self.vectors):\n",
    "            distance = dist_func(query_vector, stored_vector)\n",
    "            distances.append((distance, self.documents[i]))\n",
    "\n",
    "        distances.sort(key=lambda item: item[0])\n",
    "\n",
    "        return [(doc, dist) for dist, doc in distances[:k]]\n",
    "\n",
    "    def add_vector(self, vector, document: Dict[str, Any]):\n",
    "        if not isinstance(vector, list) or not all(\n",
    "            isinstance(x, (int, float)) for x in vector\n",
    "        ):\n",
    "            raise TypeError(\"Vector must be a list of numbers.\")\n",
    "        if not isinstance(document, dict):\n",
    "            raise TypeError(\"Document must be a dictionary.\")\n",
    "        if \"content\" not in document:\n",
    "            raise ValueError(\n",
    "                \"Document dictionary must contain a 'content' key.\"\n",
    "            )\n",
    "\n",
    "        if not self.vectors:\n",
    "            self._vector_dim = len(vector)\n",
    "        elif len(vector) != self._vector_dim:\n",
    "            raise ValueError(\n",
    "                f\"Inconsistent vector dimension. Expected {self._vector_dim}, got {len(vector)}\"\n",
    "            )\n",
    "\n",
    "        self.vectors.append(list(vector))\n",
    "        self.documents.append(document)\n",
    "\n",
    "    def _euclidean_distance(\n",
    "        self, vec1: List[float], vec2: List[float]\n",
    "    ) -> float:\n",
    "        if len(vec1) != len(vec2):\n",
    "            raise ValueError(\"Vectors must have the same dimension\")\n",
    "        return math.sqrt(sum((p - q) ** 2 for p, q in zip(vec1, vec2)))\n",
    "\n",
    "    def _dot_product(self, vec1: List[float], vec2: List[float]) -> float:\n",
    "        if len(vec1) != len(vec2):\n",
    "            raise ValueError(\"Vectors must have the same dimension\")\n",
    "        return sum(p * q for p, q in zip(vec1, vec2))\n",
    "\n",
    "    def _magnitude(self, vec: List[float]) -> float:\n",
    "        return math.sqrt(sum(x * x for x in vec))\n",
    "\n",
    "    def _cosine_distance(self, vec1: List[float], vec2: List[float]) -> float:\n",
    "        if len(vec1) != len(vec2):\n",
    "            raise ValueError(\"Vectors must have the same dimension\")\n",
    "\n",
    "        mag1 = self._magnitude(vec1)\n",
    "        mag2 = self._magnitude(vec2)\n",
    "\n",
    "        if mag1 == 0 and mag2 == 0:\n",
    "            return 0.0\n",
    "        elif mag1 == 0 or mag2 == 0:\n",
    "            return 1.0\n",
    "\n",
    "        dot_prod = self._dot_product(vec1, vec2)\n",
    "        cosine_similarity = dot_prod / (mag1 * mag2)\n",
    "        cosine_similarity = max(-1.0, min(1.0, cosine_similarity))\n",
    "\n",
    "        return 1.0 - cosine_similarity\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.vectors)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        has_embed_fn = \"Yes\" if self._embedding_fn else \"No\"\n",
    "        return f\"VectorIndex(count={len(self)}, dim={self._vector_dim}, metric='{self._distance_metric}', has_embedding_fn='{has_embed_fn}')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82431234",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = generate_embedding(chunks)\n",
    "store = VectorIndex()\n",
    "for embedding, chunk in zip(embeddings, chunks):\n",
    "   store.add_vector(embedding, {\"content\": chunk})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "298f6094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48331830503085815 \n",
      " Section 2: Software Engineering - Project Phoenix Stability Enhancements\n",
      "\n",
      "The Software Engineering division dedicated considerable effort to improving the stability and performance of the core systems \n",
      "\n",
      "0.4888823735702068 \n",
      " Future Directions\n",
      "\n",
      "This year's cross-domain insights underscore the interconnectedness of our diverse research and operational activities. The stability enhancements achieved in Software Engineering ( \n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_embedding = generate_embedding(\"What did the software engineering dept do last year?\")\n",
    "results = store.search(user_embedding, 2)\n",
    "for doc, distance in results:\n",
    "   print(distance, \"\\n\", doc[\"content\"][0:200], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542e89b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
